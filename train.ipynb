{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FinalTrial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1dbx_BxcFyuJ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDBdn2opxHt-",
        "colab_type": "text"
      },
      "source": [
        "#  Mount google drive, install dependencies and import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Q5Y0eA2_bnH",
        "colab": {}
      },
      "source": [
        "# Run this cell if running on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/My Drive/Transformer/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg0bJtSNtnoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install transformers\n",
        "!pip install transformers==2.11.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gcmj8Cb9a4aN",
        "colab": {}
      },
      "source": [
        "# Import required packages\n",
        "import torch\n",
        "import os.path\n",
        "from os import path\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils import data\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "from src import utils\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2lsWm2Pw6cI",
        "colab_type": "text"
      },
      "source": [
        "# Retrieve training and validation data from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGQUVElitnoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,Y_train = [],[]  \n",
        "fileX = open(\"train/train.token.sbt\")\n",
        "fileY = open(\"train/train.token.nl\")\n",
        "\n",
        "for lineX, lineY in zip(fileX, fileY):\n",
        "  X_train.append(lineX)\n",
        "  Y_train.append(lineY)\n",
        "\n",
        "print(\"Number of Training Example: \", len(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LSCj9GE0EDLy",
        "colab": {}
      },
      "source": [
        "X_valid,Y_valid = [],[]\n",
        "fileX = open(\"val/valid.token.sbt\")\n",
        "fileY = open(\"val/valid.token.nl\")\n",
        "\n",
        "for lineX, lineY in zip(fileX, fileY):\n",
        "  X_valid.append(lineX)\n",
        "  Y_valid.append(lineY)\n",
        "print(\"Number of validation Example: \", len(X_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoTVEU8JxZEP",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Class to load data while training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2swvO7qqbAb6",
        "colab": {}
      },
      "source": [
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, X_item, Y_item):\n",
        "    self.X_item=X_item\n",
        "    self.Y_item=Y_item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X_item)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = self.X_item[index]\n",
        "    \n",
        "    Y = self.Y_item[index]\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5eMChy8xr2n",
        "colab_type": "text"
      },
      "source": [
        "# Take GPU into action and define batch size and num of workers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4jFm-_ywbY7z",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\">>> \", device)\n",
        "params = {'batch_size': 4,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "\n",
        "params_valid = {'batch_size': 4,\n",
        "          'shuffle': False,\n",
        "          'num_workers': 0}\n",
        "\n",
        "training_set = Dataset(X_train,Y_train)\n",
        "training_generator = data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = Dataset(X_valid,Y_valid)\n",
        "validation_generator = data.DataLoader(validation_set, **params_valid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbczArvhLota",
        "colab_type": "text"
      },
      "source": [
        "## Load Initial Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU75oQWmEW1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load pre-trained model and tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "model = model.to(device)\n",
        "\n",
        "#load opptimizer\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = []\n",
        "lr=1e-4\n",
        "for key, value in dict(model.named_parameters()).items():\n",
        "    if value.requires_grad:\n",
        "        if any(nd in key for nd in no_decay):\n",
        "            optimizer_grouped_parameters += [\n",
        "                {\"params\": [value], \"lr\": lr, \"weight_decay\": 0.01}\n",
        "            ]\n",
        "        if not any(nd in key for nd in no_decay):\n",
        "            optimizer_grouped_parameters += [\n",
        "                {\"params\": [value], \"lr\": lr, \"weight_decay\": 0.0}\n",
        "            ]\n",
        "                \n",
        "optimizer = utils.BertAdam(\n",
        "            optimizer_grouped_parameters,\n",
        "            lr=lr,\n",
        "            warmup=0.1,\n",
        "            t_total=100,\n",
        "            schedule='warmup_constant',\n",
        "        )\n",
        "\n",
        "# Training variables\n",
        "\n",
        "loss_train = []\n",
        "loss_valid = []\n",
        "trainloss=0\n",
        "validloss=0\n",
        "epoch = 0\n",
        "num_epoch = 35\n",
        "model_name = \"checkpoint.pth\"\n",
        "model_location = \"models/\" + model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woUBiGfqyFOJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Load model, tokenizer, optimizer, trainer, epoch no. and losses from a checkpoint directly or from the saved location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VScZuyPaJGNF",
        "colab": {}
      },
      "source": [
        "if path.exists(model_location):\n",
        "\n",
        "  #load saved model from the drive\n",
        "  checkpoint = torch.load(model_location)\n",
        "  epoch = checkpoint['epoch']\n",
        "  model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  loss_train = checkpoint['trainloss']\n",
        "  loss_valid = checkpoint['validloss']\n",
        "  print(\">>> loaded saved checkpoint from epoch \", epoch)\n",
        "  model = model.to(device)\n",
        "\n",
        "else:\n",
        "  print(\">>> loaded from downloaded model \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk_1Q9IM3UIb",
        "colab_type": "text"
      },
      "source": [
        "## Plot train and valid loss to see the curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlO76k5A3Tek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(loss_train, color=\"green\")\n",
        "plt.plot(loss_valid, color=\"red\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj9ybabTmpBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_f1=checkpoint['F1']\n",
        "best_model=checkpoint\n",
        "if path.exists(\"models/best.pth\"):\n",
        "  best_model = torch.load(\"models/best.pth\")\n",
        "  best_f1=best_model['F1']\n",
        "print(best_f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZLmEfJAyNVa",
        "colab_type": "text"
      },
      "source": [
        "# Training and validation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6zQaAWNlcBK-",
        "colab": {}
      },
      "source": [
        "while epoch < num_epoch:\n",
        "\n",
        "  trainloss = 0\n",
        "  validloss = 0  \n",
        "  print(\"Running EPOCH : \", epoch+1)\n",
        "\n",
        "  \"\"\"Training\"\"\"\n",
        "  model.train()\n",
        "  for local_batch, local_labels in tqdm(training_generator): \n",
        "\n",
        "\n",
        "    \"\"\"Forward Function Implementation\"\"\"\n",
        "    input_ids = tokenizer.batch_encode_plus(local_batch, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "    label = tokenizer.batch_encode_plus(local_labels, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "    \n",
        "    outputs = model(input_ids=(input_ids['input_ids']).to(device), lm_labels=(label['input_ids']).to(device),attention_mask=(input_ids['attention_mask']).to(device))\n",
        "    loss = outputs[0]\n",
        "    \"\"\"Forward Function Ends here\"\"\"\n",
        "    \n",
        "    \"\"\"Loss and optimizer\"\"\"\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    trainloss += round(loss.data.item(), 4)\n",
        "\n",
        "  trainloss = trainloss/len(training_generator)\n",
        "  loss_train.append(trainloss)\n",
        "\n",
        "  \"\"\"Validation\"\"\"\n",
        "  model.eval()\n",
        "  with torch.set_grad_enabled(False):\n",
        "    refs_list = []\n",
        "    hyp_list = []\n",
        "    for local_batch, local_labels in tqdm(validation_generator):\n",
        "      input_ids = tokenizer.batch_encode_plus(local_batch, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "      label = tokenizer.batch_encode_plus(local_labels, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "      \n",
        "      outputs = model(input_ids=(input_ids['input_ids']).to(device), lm_labels=(label['input_ids']).to(device))\n",
        "\n",
        "      predY = model.generate(input_ids=(input_ids['input_ids']).to(device))\n",
        "          \n",
        "      for i,j in zip(predY, local_labels):\n",
        "        hyp_list.append(tokenizer.decode(i))\n",
        "        refs_list.append(j)\n",
        "        \n",
        "      validloss += round(outputs[0].data.item(), 4)   \n",
        "\n",
        "  validloss = validloss / len(validation_generator)\n",
        "  loss_valid.append(validloss)\n",
        "\n",
        "  precision, recall, f1, accuracy = utils.calculate_results(refs_list, hyp_list)  \n",
        "\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.plot(loss_train, color='green', label=\"Train Loss\")\n",
        "  plt.plot(loss_valid, color='red', label=\"Valid Loss\")\n",
        "  \n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\nEpoch \", epoch+1, \" completed! \\nTrain loss is: \", trainloss, \"\\nValid loss is: \", validloss)  \n",
        "  \n",
        "  print(\"For Epoch:\",epoch+1)\n",
        "  print(\"Precision: \", precision)\n",
        "  print(\"Recall: \", recall)\n",
        "  print(\"f1: \", f1)\n",
        "  print(\"Accuracy: \", accuracy)\n",
        "  \"\"\"Save states\"\"\"\n",
        "  states = {\n",
        "          'epoch': epoch + 1,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "          'trainloss': loss_train,\n",
        "          'validloss': loss_valid,\n",
        "          'F1': f1\n",
        "      }\n",
        "  if f1>best_f1:\n",
        "    best_f1=f1\n",
        "    print(\"Saving the best model\")\n",
        "    torch.save(states, \"models/best.pth\")\n",
        "  \n",
        "  print(\"Saving the regular model\")\n",
        "  torch.save(states, \"models/\" + model_name)\n",
        "\n",
        "  rand = random.randint(0,19999)\n",
        "\n",
        "  print(\"Random example from valid set:\\n\")\n",
        "  print(\"TARGET: \" + refs_list[rand] + \"\\n\")\n",
        "  print(\"Prediction: \" + hyp_list[rand] + \"\\n\")\n",
        "  print(\"\\n\", \"_\"*100 , \"\\n\\n\")\n",
        "\n",
        "  epoch += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffadmlCuxIWM",
        "colab_type": "text"
      },
      "source": [
        "## Load Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvO7ZYj3lPWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.plot(loss_valid, color='red', label=\"Valid Loss\")\n",
        "plt.plot(loss_train, color='blue', label=\"Train Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5pxbcJIEhUcL",
        "colab": {}
      },
      "source": [
        "X_test,Y_test = [],[]\n",
        "file=open(\"test/test.token.sbt\")\n",
        "for line in file:\n",
        "  X_test.append(line)\n",
        "file=open(\"test/test.token.nl\")\n",
        "for line in file:\n",
        "  Y_test.append(line)\n",
        "\n",
        "print(len(X_test))\n",
        "  \n",
        "# Data loader for test set\n",
        "test_set = Dataset(X_test,Y_test)\n",
        "test_generator = data.DataLoader(test_set, **params_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ2fIeC_xkc2",
        "colab_type": "text"
      },
      "source": [
        "## Make target and predicted list\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKJ2rFRQxp7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "refs_list = []\n",
        "hyp_list = []\n",
        "\n",
        "model.eval()\n",
        "with torch.set_grad_enabled(False):\n",
        "  for local_batch, local_labels in tqdm(test_generator):\n",
        "    input_ids = tokenizer.batch_encode_plus(local_batch, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "    \n",
        "    predY = model.generate(input_ids=(input_ids['input_ids']).to(device))\n",
        "    \n",
        "    for i,j in zip(predY, local_labels):\n",
        "      hyp_list.append(tokenizer.decode(i))\n",
        "      refs_list.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7zLMHn0lfGn",
        "colab_type": "text"
      },
      "source": [
        "## Calculate Precision, Recall, f1 and Accuracy on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmId2AutxT2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision, recall, f1, accuracy = utils.calculate_results(refs_list, hyp_list)\n",
        "rand = random.randint(0,19999)\n",
        "\n",
        "for i in range(40):\n",
        "  print(\"TARGET: \" + refs_list[rand+i])\n",
        "  print(\"Prediction: \" + hyp_list[rand+i] + \"\\n\\n\")\n",
        "\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"f1: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2xek1rHmgBh",
        "colab_type": "text"
      },
      "source": [
        "## Calculat Bleu Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwjjFE5Gb_GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open(\"src/reference.txt\", \"w\")\n",
        "for i in range(len(refs_list)):\n",
        "  if(i > 1):\n",
        "    f.write(refs_list[i])\n",
        "f.close()\n",
        "f = open(\"src/hypothesis.txt\", \"w\")\n",
        "for i in range(len(hyp_list)):\n",
        "  if(i > 1):\n",
        "    f.write(hyp_list[i] + \"\\n\")\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9kHeuUacubC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd src\n",
        "%%perl multi-bleu.perl reference.txt hypothesis.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCx-3B6vw8MB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoothie = SmoothingFunction().method7\n",
        "bleu_score = 0.0\n",
        "refs=[]\n",
        "hyp=[]\n",
        "for i in range(len(refs_list)):\n",
        "  refs.append(refs_list[i].strip().split())\n",
        "  hyp.append(hyp_list[i].strip().split())\n",
        "print(hyp)\n",
        "#bleu_score2 = corpus_bleu(refs, hyp,smoothing_function=smoothie)\n",
        "bleu_score2 = corpus_bleu(refs, hyp)\n",
        "print(\"The bleu score is: \"+str(bleu_score2*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}