{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "firstTrial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nhPCWeEdpyWpxOTSVCFr6j7UW9sdNjeO",
      "authorship_tag": "ABX9TyNajIPpYSDzocxkVmIaXB+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codekali/Neural-SC-Desciptor/blob/master/firstTrial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcmj8Cb9a4aN",
        "colab_type": "code",
        "outputId": "9272ad71-ea8f-4eb1-c918-f9b3e4f9c5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "dictionary={}\n",
        "X,Y = [],[]\n",
        "count=-1   \n",
        "file=open(\"/content/drive/My Drive/Transformer/train/train.token.sbt\")\n",
        "for line in file:\n",
        "  X.append(line)\n",
        "  count+=1\n",
        "count=0\n",
        "file=open(\"/content/drive/My Drive/Transformer/train/train.token.nl\")\n",
        "for line in file:\n",
        "  Y.append(line)\n",
        "  count+=1\n",
        "print(len(Y))\n",
        "print(len(X))\n",
        "X=X[0:1000]\n",
        "Y=Y[0:1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "445812\n",
            "445812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSCj9GE0EDLy",
        "colab_type": "code",
        "outputId": "e69044c3-8299-4297-fb55-b974de41feb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "dictionary={}\n",
        "X_valid,Y_valid = [],[]\n",
        "count=-1   \n",
        "file=open(\"/content/drive/My Drive/Transformer/val/valid.token.sbt\")\n",
        "for line in file:\n",
        "  X_valid.append(line)\n",
        "  count+=1\n",
        "count=0\n",
        "file=open(\"/content/drive/My Drive/Transformer/val/valid.token.nl\")\n",
        "for line in file:\n",
        "  Y_valid.append(line)\n",
        "  count+=1\n",
        "print(len(Y_valid))\n",
        "print(len(X_valid))\n",
        "X_valid=X_valid[0:100]\n",
        "Y_valid=Y_valid[0:100]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000\n",
            "20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E65v5JOxdj99",
        "colab_type": "code",
        "outputId": "8575abdb-3ca0-46e7-98f8-c1b31f700ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(Y))\n",
        "print(len(X))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2swvO7qqbAb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, X_item, Y_item):\n",
        "    self.X_item=X_item\n",
        "    self.Y_item=Y_item\n",
        "    self.device=device\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.X_item)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = self.X_item[index]\n",
        "    Y = self.Y_item[index]\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jFm-_ywbY7z",
        "colab_type": "code",
        "outputId": "1d47afbc-f1e8-4180-a133-17a77bdc689a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import mydata\n",
        "import torch\n",
        "from torch.utils import data\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "#cudann.benchmark = True\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 5,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 6}\n",
        "max_epochs = 10\n",
        "\n",
        "training_set = Dataset(X,Y)\n",
        "training_generator = data.DataLoader(training_set, **params)\n",
        "\n",
        "validation_set = Dataset(X_valid,Y_valid)\n",
        "validation_generator = data.DataLoader(validation_set, **params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LgliBxibZKp",
        "colab_type": "code",
        "outputId": "75d1862e-354a-4670-ebed-d7355a13381c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zQaAWNlcBK-",
        "colab_type": "code",
        "outputId": "9a7bf882-c56b-4f25-8881-80037f0bb6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch.optim as optim\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "model = model.to(device)\n",
        "for epoch in range(15):\n",
        "    trainloss=0\n",
        "    validloss=0\n",
        "    # Training\n",
        "    for local_batch, local_labels in training_generator: \n",
        "        \"\"\"Transfer local_batch and labels to GPU\"\"\"\n",
        "        #local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
        "        \"\"\" You can write the above statement as:\n",
        "        local_batch=(x.to(device) for x in local_batch)\n",
        "        local_labels=(x.to(device) for x in local_labels)\n",
        "        But I have transfered them to the device after encoding them\n",
        "        \"\"\"\n",
        "        \"\"\"Forward Function Implementation\"\"\"\n",
        "        input_ids = tokenizer.batch_encode_plus(local_batch, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "        label = tokenizer.batch_encode_plus(local_labels, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "        outputs = model(input_ids=(input_ids['input_ids']).to(device), lm_labels=(label['input_ids']).to(device))\n",
        "        loss, prediction_scores = outputs[:2]\n",
        "        trainloss=loss\n",
        "        #print(loss)\n",
        "        \"\"\"Forward Function Ends here\"\"\"\n",
        "        \"\"\"Loss and optimizer\"\"\"\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "        optimizer.zero_grad()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    \"\"\"Validation\"\"\"\n",
        "    with torch.set_grad_enabled(False):\n",
        "        for local_batch, local_labels in validation_generator:\n",
        "          input_ids = tokenizer.batch_encode_plus(local_batch, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "          label = tokenizer.batch_encode_plus(local_labels, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "          model.eval()\n",
        "          outputs = model(input_ids=(input_ids['input_ids']).to(device), lm_labels=(label['input_ids']).to(device))\n",
        "          loss, prediction_scores = outputs[:2]\n",
        "          validloss=loss\n",
        "    print(\"\\nEpoch \", epoch, \" completed!, Training LOSS is: \", trainloss, \" Validation loss is: \", validloss)\n",
        "    #print(loss, \"\\n\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch  0  completed!, Training LOSS is:  tensor(20.8415, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(10.0547, device='cuda:0')\n",
            "\n",
            "Epoch  1  completed!, Training LOSS is:  tensor(11.9161, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(16.9352, device='cuda:0')\n",
            "\n",
            "Epoch  2  completed!, Training LOSS is:  tensor(18.0669, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(19.1240, device='cuda:0')\n",
            "\n",
            "Epoch  3  completed!, Training LOSS is:  tensor(20.4952, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(19.1648, device='cuda:0')\n",
            "\n",
            "Epoch  4  completed!, Training LOSS is:  tensor(16.0663, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(16.6882, device='cuda:0')\n",
            "\n",
            "Epoch  5  completed!, Training LOSS is:  tensor(12.5693, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(17.0689, device='cuda:0')\n",
            "\n",
            "Epoch  6  completed!, Training LOSS is:  tensor(22.4999, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(15.9427, device='cuda:0')\n",
            "\n",
            "Epoch  7  completed!, Training LOSS is:  tensor(10.9391, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(7.6967, device='cuda:0')\n",
            "\n",
            "Epoch  8  completed!, Training LOSS is:  tensor(17.2467, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(13.2819, device='cuda:0')\n",
            "\n",
            "Epoch  9  completed!, Training LOSS is:  tensor(21.0187, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(12.9119, device='cuda:0')\n",
            "\n",
            "Epoch  10  completed!, Training LOSS is:  tensor(9.2573, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(19.0192, device='cuda:0')\n",
            "\n",
            "Epoch  11  completed!, Training LOSS is:  tensor(13.6382, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(12.0085, device='cuda:0')\n",
            "\n",
            "Epoch  12  completed!, Training LOSS is:  tensor(20.1329, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(19.7693, device='cuda:0')\n",
            "\n",
            "Epoch  13  completed!, Training LOSS is:  tensor(26.6254, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(22.6960, device='cuda:0')\n",
            "\n",
            "Epoch  14  completed!, Training LOSS is:  tensor(10.9508, device='cuda:0', grad_fn=<NllLossBackward>)  Validation loss is:  tensor(7.8972, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMdN-HAVDuGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXLsw4qsNmPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime as dt\n",
        "runtime =  dt.now()\n",
        "model_name = \"/content/drive/My Drive/Transformer/models/\" + now.strftime(\"%d/%m/%Y %H:%M\") + \".pth\"\n",
        "\n",
        "torch.save(model.state_dict(), model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}