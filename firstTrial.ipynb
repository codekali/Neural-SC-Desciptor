{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "firstTrial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nhPCWeEdpyWpxOTSVCFr6j7UW9sdNjeO",
      "authorship_tag": "ABX9TyNisjqN2xTvIrS5m7OFSEkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codekali/Neural-SC-Desciptor/blob/master/firstTrial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcmj8Cb9a4aN",
        "colab_type": "code",
        "outputId": "81b09ed0-4ee4-465c-f7bf-7a2f9fbef74e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import torch\n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "dictionary={}\n",
        "X,Y = [],[]\n",
        "count=-1   \n",
        "file=open(\"/content/drive/My Drive/Transformer/train.token.sbt\")\n",
        "for line in file:\n",
        "  X.append(line)\n",
        "  count+=1\n",
        "count=0\n",
        "file=open(\"/content/drive/My Drive/Transformer/train.token.nl\")\n",
        "for line in file:\n",
        "  Y.append(line)\n",
        "  count+=1\n",
        "print(len(Y))\n",
        "print(len(X))\n",
        "X=X[0:15]\n",
        "Y=Y[0:15]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "445812\n",
            "445812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E65v5JOxdj99",
        "colab_type": "code",
        "outputId": "75662f8f-dd2e-4d41-f6cc-cbca070752f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(len(Y))\n",
        "print(len(X))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2swvO7qqbAb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, X_item, Y_item):\n",
        "    self.X_item=X_item\n",
        "    self.Y_item=Y_item\n",
        "    self.device=device\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.X_item)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = self.X_item[index]\n",
        "    Y = self.Y_item[index]\n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jFm-_ywbY7z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30ea8526-6401-487a-df18-ffaa26a43327"
      },
      "source": [
        "#import mydata\n",
        "import torch\n",
        "from torch.utils import data\n",
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "#cudann.benchmark = True\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 5,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 6}\n",
        "max_epochs = 10\n",
        "\n",
        "training_set = Dataset(X,Y)\n",
        "training_generator = data.DataLoader(training_set, **params)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LgliBxibZKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "b8d0391f-e911-4d1b-b5b7-acb4b622e35b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 23.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 34.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 19.4MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 13.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 14.1MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 12.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 12.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 49.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 54.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=22bbf60f8cf35f54fc72fb6edf6c9599c1ece720ea25df929d70b41be084fa7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zQaAWNlcBK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "3c0fd3f3-f4db-4510-a854-7058abc9e108"
      },
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch.optim as optim\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('/content/drive/My Drive/Transformer/spiece.model')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "model = model.to(device)\n",
        "for epoch in range(2):\n",
        "    loss=0\n",
        "    # Training\n",
        "    for local_batch, local_labels in training_generator: \n",
        "        \"\"\"Transfer local_batch and labels to GPU\"\"\"\n",
        "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
        "\n",
        "        \"\"\"Forward Function Implementation\"\"\"\n",
        "        input_ids = tokenizer.batch_encode_plus(local_batch, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "        label = tokenizer.batch_encode_plus(local_labels, return_tensors=\"pt\",pad_to_max_length=True)\n",
        "        outputs = model(input_ids=(input_ids['input_ids']).to(device), lm_labels=(label['input_ids']).to(device))\n",
        "        loss, prediction_scores = outputs[:2]\n",
        "        print(loss)\n",
        "        \"\"\"Forward Function Ends here\"\"\"\n",
        "        \"\"\"Loss and optimizer\"\"\"\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "        optimizer.zero_grad()\n",
        "        optimizer.step()\n",
        "    print(\"Done one epoch\\n\\n\\n\")\n",
        "    print(loss)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling T5Tokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-441aaba83bbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"\"\"Transfer local_batch and labels to GPU\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlocal_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;34m\"\"\"Forward Function Implementation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'cuda'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbF5dQlu4bww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}